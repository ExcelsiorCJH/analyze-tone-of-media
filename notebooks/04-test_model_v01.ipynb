{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train BiLSTM + Attn Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from functools import partial\n",
    "from collections import OrderedDict, defaultdict\n",
    "\n",
    "import yaml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from experiment import Experiment\n",
    "from models import BiLSTMAttn\n",
    "from utils import NewsDataset, collate_fn\n",
    "from utils.types_ import *\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "GPU_NUM = 1\n",
    "DEVICE = torch.device(f\"cuda:{GPU_NUM}\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01. data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = \"./config.yaml\"\n",
    "with open(config_path, \"r\") as file:\n",
    "    try:\n",
    "        config = yaml.safe_load(file)\n",
    "    except yaml.YAMLError as exc:\n",
    "        print(exc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------\n",
    "# DataLoader\n",
    "# ----------------\n",
    "data_path = config[\"exp_params\"][\"data_path\"]\n",
    "vocab_path = config[\"exp_params\"][\"vocab_path\"]\n",
    "labels_list = [\"조선일보\", \"동아일보\", \"경향신문\", \"한겨레\"]\n",
    "labels_dict = {label: idx for idx, label in enumerate(labels_list)}\n",
    "\n",
    "with open(vocab_path, \"rb\") as f:\n",
    "    word_index = pickle.load(f)\n",
    "\n",
    "\n",
    "dataset = NewsDataset(data_path)\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=False,\n",
    "    collate_fn=partial(collate_fn, word_index=word_index, labels_dict=labels_dict),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02. Model load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = \"../checkpoints/BilstmAttn_epoch=29_val_loss=0.05.ckpt\"\n",
    "\n",
    "checkpoint = torch.load(ckpt_path)\n",
    "checkpoint[\"state_dict\"] = OrderedDict(\n",
    "    [(key.replace(\"model.\", \"\"), val) for key, val in checkpoint[\"state_dict\"].items()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BiLSTMAttn(\n",
       "  (embed): Embedding(30002, 128, padding_idx=0)\n",
       "  (bilstm): LSTM(128, 256, num_layers=2, batch_first=True, dropout=0.3, bidirectional=True)\n",
       "  (linear): Linear(in_features=512, out_features=4, bias=True)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vocab_size & num_class\n",
    "config[\"model_params\"][\"vocab_size\"] = len(word_index)\n",
    "config[\"model_params\"][\"num_class\"] = len(labels_list)\n",
    "\n",
    "model = BiLSTMAttn(**config[\"model_params\"]).to(DEVICE)\n",
    "model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03. Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) 각 키워드-언론사 별 단어의 attention score 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 263/263 [00:10<00:00, 25.59it/s]\n"
     ]
    }
   ],
   "source": [
    "top_k = 20\n",
    "index_word = {idx: word for word, idx in word_index.items()}\n",
    "index_label = {idx: label for label, idx in labels_dict.items()}\n",
    "result_dict = defaultdict(lambda: defaultdict(lambda: defaultdict(list)))\n",
    "\n",
    "for batch in tqdm(test_loader):\n",
    "    sequences, labels, keywords = batch\n",
    "    sequences = sequences.to(DEVICE)\n",
    "\n",
    "    labels = [index_label[label] for label in labels.tolist()]\n",
    "    _, attn_scores = model(sequences)\n",
    "\n",
    "    for keyword, label, attn_score, sequence in zip(\n",
    "        keywords, labels, attn_scores, sequences\n",
    "    ):\n",
    "\n",
    "        topk_attns, topk_idxs = torch.topk(attn_score, top_k)\n",
    "        topk_attns = topk_attns.tolist()\n",
    "        topk_seq = sequence[topk_idxs].tolist()\n",
    "\n",
    "        result = [\n",
    "            (index_word[seq], score)\n",
    "            for seq, score in zip(topk_seq, topk_attns)\n",
    "            if seq > 1\n",
    "        ]\n",
    "\n",
    "        for word, score in result:\n",
    "            if len(word) > 1:\n",
    "                result_dict[keyword][label][word].append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "media_keyword_dict = defaultdict(lambda: defaultdict(lambda: defaultdict(float)))\n",
    "for keyword, media_dict in result_dict.items():\n",
    "    for media, word_dict in media_dict.items():\n",
    "        for word, vals in word_dict.items():\n",
    "            media_keyword_dict[keyword][media][word] = np.sum(vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) 각 키워드-언론사별 상관계수 구하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = [\"필리버스터\", \"탄핵\", \"드루킹\", \"남북회담\", \"조국\"]\n",
    "medias = [\"조선일보\", \"동아일보\", \"경향신문\", \"한겨레\"]\n",
    "media_comb = list(combinations(medias, 2))\n",
    "corr_dict = defaultdict(list)\n",
    "for keyword in keywords:\n",
    "    for m1, m2 in media_comb:\n",
    "        m1_words = sorted(\n",
    "            media_keyword_dict[keyword][m1].items(), key=lambda x: x[1], reverse=True\n",
    "        )[:100]\n",
    "        m2_words = sorted(\n",
    "            media_keyword_dict[keyword][m2].items(), key=lambda x: x[1], reverse=True\n",
    "        )[:100]\n",
    "        df1 = pd.DataFrame(\n",
    "            m1_words, columns=[f\"{keyword}_{m1}_단어\", f\"{keyword}_{m1}_점수\"]\n",
    "        )\n",
    "        df2 = pd.DataFrame(\n",
    "            m2_words, columns=[f\"{keyword}_{m2}_단어\", f\"{keyword}_{m2}_점수\"]\n",
    "        )\n",
    "        df3 = df1.merge(\n",
    "            df2,\n",
    "            how=\"inner\",\n",
    "            left_on=f\"{keyword}_{m1}_단어\",\n",
    "            right_on=f\"{keyword}_{m2}_단어\",\n",
    "        )\n",
    "        corr = np.corrcoef(\n",
    "            df3[f\"{keyword}_{m1}_점수\"].values, df3[f\"{keyword}_{m2}_점수\"].values\n",
    "        )[0, 1]\n",
    "        corr_dict[keyword].append((f\"{m1}-{m2}\", corr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('조선일보-동아일보', 0.7272041372627024),\n",
       " ('조선일보-경향신문', 0.46991132026884136),\n",
       " ('조선일보-한겨레', 0.34387486764558295),\n",
       " ('동아일보-경향신문', 0.5519848021533316),\n",
       " ('동아일보-한겨레', 0.4877613094702468),\n",
       " ('경향신문-한겨레', 0.7343701182189166)]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_dict[\"조국\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) 각 키워드-언론사별 상관계수 가설검정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N = 100\n",
    "# pval_dict = defaultdict(list)\n",
    "# rho_list = np.arange(0, 1, 0.01)\n",
    "# for rho in rho_list:\n",
    "#     for keyword, corrs in corr_dict.items():\n",
    "#         for m1m2, corr in corrs:\n",
    "#             t = (corr - rho) / np.sqrt((1 - corr ** 2) / (N - 2))\n",
    "#             pval = stats.t.sf(t, N - 1) * 2\n",
    "#             pval_dict[keyword].append((m1m2, rho, pval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100\n",
    "pval_dict = defaultdict(lambda: defaultdict(list))\n",
    "rho_list = np.arange(0, 1, 0.01)\n",
    "for rho in rho_list:\n",
    "    for keyword, corrs in corr_dict.items():\n",
    "        for m1m2, corr in corrs:\n",
    "            t = (corr - rho) / np.sqrt((1 - corr ** 2) / (N - 2))\n",
    "            pval = stats.t.sf(t, N - 1) * 2\n",
    "            pval_dict[keyword][m1m2].append((rho, pval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "pval_max_dict = defaultdict(list)\n",
    "for keyword, mp_dict in pval_dict.items():\n",
    "    for m1m2, pvals in mp_dict.items():\n",
    "        pval_maxs = [(rho, pval) for rho, pval in pvals if pval <= 0.05]\n",
    "        try:\n",
    "            rho, p_max = max(pval_maxs, key=lambda x: x[1])\n",
    "        except:\n",
    "            rho, p_max = \"x\", \"x\"\n",
    "        pval_max_dict[keyword].append((m1m2, rho, p_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'필리버스터': [('조선일보-동아일보', 0.59, 0.04844332610540452),\n",
       "              ('조선일보-경향신문', 0.35000000000000003, 0.04660600101154737),\n",
       "              ('조선일보-한겨레', 0.67, 0.03659845970067276),\n",
       "              ('동아일보-경향신문', 0.29, 0.046351449461411516),\n",
       "              ('동아일보-한겨레', 0.44, 0.044139099181635486),\n",
       "              ('경향신문-한겨레', 0.5700000000000001, 0.04358989977207472)],\n",
       "             '탄핵': [('조선일보-동아일보', 0.49, 0.04289258511166552),\n",
       "              ('조선일보-경향신문', 0.41000000000000003, 0.038930950932673056),\n",
       "              ('조선일보-한겨레', 0.56, 0.04075798799515275),\n",
       "              ('동아일보-경향신문', 0.25, 0.044476168506502864),\n",
       "              ('동아일보-한겨레', 0.76, 0.04076509073796321),\n",
       "              ('경향신문-한겨레', 0.85, 0.044404205792409515)],\n",
       "             '드루킹': [('조선일보-동아일보', 0.46, 0.04780008651995186),\n",
       "              ('조선일보-경향신문', 0.02, 0.04969068220697995),\n",
       "              ('조선일보-한겨레', 0.38, 0.04202903889439298),\n",
       "              ('동아일보-경향신문', 'x', 'x'),\n",
       "              ('동아일보-한겨레', 0.44, 0.047406471693737025),\n",
       "              ('경향신문-한겨레', 0.5700000000000001, 0.03619418184843925)],\n",
       "             '남북회담': [('조선일보-동아일보', 0.66, 0.03927034654140917),\n",
       "              ('조선일보-경향신문', 0.15, 0.042178603238180144),\n",
       "              ('조선일보-한겨레', 0.59, 0.03587703843576612),\n",
       "              ('동아일보-경향신문', 0.25, 0.04773579380582248),\n",
       "              ('동아일보-한겨레', 0.71, 0.041156818318301154),\n",
       "              ('경향신문-한겨레', 0.9, 0.038512097453140805)],\n",
       "             '조국': [('조선일보-동아일보', 0.58, 0.03625073598665017),\n",
       "              ('조선일보-경향신문', 0.29, 0.046331140495253956),\n",
       "              ('조선일보-한겨레', 0.15, 0.04361799444246464),\n",
       "              ('동아일보-경향신문', 0.38, 0.04383117553203266),\n",
       "              ('동아일보-한겨레', 0.31, 0.046530700494571024),\n",
       "              ('경향신문-한겨레', 0.59, 0.037767227887780974),\n",
       "              ('조선일보-동아일보?', 'x', 'x')],\n",
       "             '필리버스터?': [('조선일보-동아일보', 'x', 'x')]})"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pval_max_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
